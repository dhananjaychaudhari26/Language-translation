{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k_AlAuKJqVA"
   },
   "source": [
    "<font color='blue'>**Load the data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fU80Ao-AGaob"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421765, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>russian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Марш!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Иди.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Идите.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Здравствуйте.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Привет!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english        russian\n",
       "0     Go.          Марш!\n",
       "1     Go.           Иди.\n",
       "2     Go.         Идите.\n",
       "3     Hi.  Здравствуйте.\n",
       "4     Hi.        Привет!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('rus-eng/rus.txt', 'r', encoding=\"utf8\") as f:\n",
    "    eng=[]\n",
    "    rus=[]\n",
    "    for i in f.readlines():\n",
    "        splited_string = i.split(\"\\t\")\n",
    "        eng.append(splited_string[0])\n",
    "        rus.append(splited_string[1])\n",
    "data = pd.DataFrame(data=zip(eng, rus), columns=['english','russian'])\n",
    "print(data.shape)\n",
    "del eng,rus\n",
    "gc.collect()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmGWTdRmKRph"
   },
   "source": [
    "<font color='blue'>**Preprocess data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9QqElB_nKZos"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>russian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>марш</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>иди</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go</td>\n",
       "      <td>идите</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi</td>\n",
       "      <td>здравствуйте</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>привет</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english       russian\n",
       "0      go          марш\n",
       "1      go           иди\n",
       "2      go         идите\n",
       "3      hi  здравствуйте\n",
       "4      hi        привет"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decontractions(phrase):\n",
    "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    # convert all the text into lower letters\n",
    "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
    "    # remove all the spacial characters: except space ' '\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_rus(text):\n",
    "    # convert all the text into lower letters\n",
    "    # remove the words betweent brakets ()\n",
    "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
    "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
    "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
    "    # you are free to do more proprocessing\n",
    "    # note that the model will learn better with better preprocessed data \n",
    "    text = text.lower()\n",
    "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
    "    text = re.sub('\\u200b', ' ', text)\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    text = re.sub('-', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "data['english'] = data['english'].apply(preprocess)\n",
    "data['russian'] = data['russian'].apply(preprocess_rus)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_lengths = data['russian'].str.split().apply(len)\n",
    "eng_lengths = data['english'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(rus_lengths,orient='v')\n",
    "print(np.percentile(rus_lengths,99.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#99.9 percentile value of input leght is 22 so we will will input lenght for seuquence to 20\n",
    "encoder_inputs_length = 16\n",
    "decoder_inputs_length = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>russian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>марш</td>\n",
       "      <td>&lt;start&gt; go</td>\n",
       "      <td>go &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>иди</td>\n",
       "      <td>&lt;start&gt; go</td>\n",
       "      <td>go &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>идите</td>\n",
       "      <td>&lt;start&gt; go</td>\n",
       "      <td>go &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>здравствуйте</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>привет</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        russian english_inp english_out\n",
       "0          марш  <start> go    go <end>\n",
       "1           иди  <start> go    go <end>\n",
       "2         идите  <start> go    go <end>\n",
       "3  здравствуйте  <start> hi    hi <end>\n",
       "4        привет  <start> hi    hi <end>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['russian_len'] = data['russian'].str.split().apply(len)\n",
    "data = data[data['russian_len'] < encoder_inputs_length]\n",
    "\n",
    "data['english_len'] = data['english'].str.split().apply(len)\n",
    "data = data[data['english_len'] < encoder_inputs_length]\n",
    "\n",
    "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
    "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
    "\n",
    "data = data.drop(['english','russian_len','english_len'], axis=1)\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378036, 3) (42004, 3)\n"
     ]
    }
   ],
   "source": [
    "train, validation = train_test_split(data, test_size=0.1)\n",
    "print(train.shape, validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
    "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16635\n",
      "16635\n",
      "54706\n"
     ]
    }
   ],
   "source": [
    "tokenizer_rus = Tokenizer()\n",
    "tokenizer_rus.fit_on_texts(data['russian'].values)\n",
    "\n",
    "tokenizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer_eng.fit_on_texts(data['english_inp'].values)\n",
    "\n",
    "tokenizer_eng_out = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer_eng_out.fit_on_texts(data['english_out'].values)\n",
    "\n",
    "vocab_size_eng=len(tokenizer_eng.word_index.keys())\n",
    "print(vocab_size_eng)\n",
    "\n",
    "vocab_size_eng_out=len(tokenizer_eng_out.word_index.keys())\n",
    "print(vocab_size_eng_out)\n",
    "\n",
    "vocab_size_rus=len(tokenizer_rus.word_index.keys())\n",
    "print(vocab_size_rus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tokenizer_rus, tokenizer_eng,tokenizer_eng_out, max_len):\n",
    "        self.encoder_inps = data['russian'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tokenizer_eng = tokenizer_eng\n",
    "        self.tokenizer_rus = tokenizer_rus\n",
    "        self.tokenizer_eng_out = tokenizer_eng_out\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tokenizer_rus.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tokenizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "   \n",
    "                \n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "\n",
    "        \n",
    "        self.decoder_target_data = self.tokenizer_eng_out.texts_to_sequences([self.decoder_outs[i]])\n",
    "        self.decoder_target_data = pad_sequences(self.decoder_target_data, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        \n",
    "        return tf.convert_to_tensor(self.encoder_seq), tf.convert_to_tensor(self.decoder_inp_seq), tf.convert_to_tensor(self.decoder_target_data)\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 16)\n"
     ]
    }
   ],
   "source": [
    "# encoder_inputs_length\n",
    "# decoder_inputs_length\n",
    "batch_size = 400\n",
    "train_dataset = Dataset(train, tokenizer_rus, tokenizer_eng,tokenizer_eng_out, encoder_inputs_length)\n",
    "test_dataset  = Dataset(validation, tokenizer_rus, tokenizer_eng,tokenizer_eng_out, encoder_inputs_length)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "print(test_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4KIsGxLOfK"
   },
   "source": [
    "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMm3ADQDLOfK"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Lx_5NA24KzRp"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.inp_vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_units = lstm_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_output = 0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "        self.embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        self.lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        \n",
    "        '''\n",
    "        This function takes a sequence input and the initial states of the encoder.\n",
    "        Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "        returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "        '''\n",
    "        input_embedd = self.embedding(input_sequence)\n",
    "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
    "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return tf.convert_to_tensor(np.zeros((batch_size,self.lstm_units)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXn278lhLYRM"
   },
   "source": [
    "<font color='blue'>**Attention**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ab5SNdPZLlur"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "  '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "  '''\n",
    "  def __init__(self,scoring_function, att_units):\n",
    "\n",
    "    super().__init__()\n",
    "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "    self.scoring_function = scoring_function\n",
    "    self.V = Dense(1)\n",
    "    if self.scoring_function=='dot':\n",
    "      # Intialize variables needed for Dot score function here\n",
    "      pass\n",
    "    if scoring_function == 'general':\n",
    "      # Intialize variables needed for General score function here\n",
    "      self.Wa = Dense(att_units)\n",
    "    elif scoring_function == 'concat':\n",
    "      # Intialize variables needed for Concat score function here\n",
    "      self.W1 = Dense(att_units)\n",
    "      self.W2 = Dense(att_units)\n",
    "      \n",
    "  \n",
    "  \n",
    "  def call(self,decoder_hidden_state,encoder_output):\n",
    "    '''\n",
    "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "    '''\n",
    "    attention_weights = []\n",
    "    context_vector = []\n",
    "#     print(decoder_hidden_state.shape)\n",
    "    if self.scoring_function == 'dot':\n",
    "        # Implement Dot score function here\n",
    "        score = self.V(tf.matmul(encoder_output,tf.reshape(decoder_hidden_state,[decoder_hidden_state.shape[0],decoder_hidden_state.shape[1],1])))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = tf.reduce_sum(attention_weights * encoder_output,axis=1)\n",
    "#         for d,e in zip(decoder_hidden_state,encoder_output):\n",
    "#             print(tf.tensordot(e,tf.reshape(d,[-1,1]),axes=1).shape)\n",
    "#             attention_weight =  self.softmax(tf.tensordot(e,tf.reshape(d,[-1,1]),axes=1))\n",
    "#             attention_weights.append(attention_weight)\n",
    "\n",
    "#             context_vector.append(tf.reduce_sum(attention_weight * e,axis=0))\n",
    "#         print(attention_weight.shape)    \n",
    "#         print(attention_weights)\n",
    "        return  tf.convert_to_tensor(context_vector) , tf.convert_to_tensor(attention_weights)\n",
    "    elif self.scoring_function == 'general':\n",
    "        score = self.V(self.Wa(tf.matmul(encoder_output,tf.reshape(decoder_hidden_state,[decoder_hidden_state.shape[0],decoder_hidden_state.shape[1],1]))))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = tf.reduce_sum(attention_weights * encoder_output,axis=1)\n",
    "        # Implement General score function here\n",
    "#         for d,e in zip(decoder_hidden_state,encoder_output):\n",
    "#             attention_weight =self.softmax(self.Wa(e*d))\n",
    "#             attention_weights.append(attention_weight)\n",
    "            \n",
    "#             vector = attention_weight * e\n",
    "#             vector = tf.reduce_sum(vector,axis=0)\n",
    "            \n",
    "#             context_vector.append(tf.reduce_sum(attention_weight * e,axis=0))\n",
    "            \n",
    "        return  tf.convert_to_tensor(context_vector) , tf.convert_to_tensor(attention_weights)   \n",
    "    elif self.scoring_function == 'concat':\n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(decoder_hidden_state) + self.W2(encoder_output)))\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * encoder_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        # Implement General score function here\n",
    "#         decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)\n",
    "#         attention_weights = self.softmax(tf.nn.tanh(self.W1(decoder_hidden_state+encoder_output)))\n",
    "#         context_vector = tf.reduce_sum(attention_weights * encoder_output,axis=1)\n",
    "#         for d,e in zip(decoder_hidden_state,encoder_output):\n",
    "            \n",
    "#             attention_weight = self.softmax(tf.nn.tanh(self.W1(d+e)))\n",
    "#             attention_weights.append(attention_weight)\n",
    "        \n",
    "#             context_vector.append(tf.reduce_sum(attention_weight * e,axis=0))            \n",
    "            \n",
    "        return  tf.convert_to_tensor(context_vector) , tf.convert_to_tensor(attention_weights)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic-FNEbfL2DN"
   },
   "source": [
    "<font color='blue'>**OneStepDecoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Kc8m7lmOL097"
   },
   "outputs": [],
   "source": [
    "class One_Step_Decoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "        self.tar_vocab_size = tar_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.score_fun = score_fun\n",
    "        self.input_length = input_length\n",
    "        self.dec_units = dec_units\n",
    "        self.att_units = att_units\n",
    "        \n",
    "        self.embedding = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,mask_zero=True, name=\"embedding_layer_one_step_deocoder\")\n",
    "        self.lstm = LSTM(self.dec_units, return_state=True, return_sequences=True, name=\"one_step_decoder_LSTM\")        \n",
    "        self.dense = Dense(tar_vocab_size)\n",
    "        \n",
    "        self.attention=Attention(score_fun,att_units)\n",
    "\n",
    "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "    '''\n",
    "        One step decoder mechanisim step by step:\n",
    "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "      C. Concat the context vector with the step A output\n",
    "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "    '''\n",
    "\n",
    "    embeding_output = self.embedding(input_to_decoder) # step A\n",
    "    \n",
    "    context_vector,attention_weights = self.attention(state_h,encoder_output)\n",
    "    context_vector = tf.expand_dims(context_vector,axis=1)\n",
    "#     print(context_vector.shape)\n",
    "    concated = tf.concat([embeding_output,context_vector],axis=2) # step C\n",
    "       \n",
    "    decode_output,out_state_h,out_state_c = self.lstm(concated,initial_state=[state_h,state_c]) # step D \n",
    "#     print(decode_output.shape)\n",
    "    output = self.dense(tf.reshape(decode_output,[tf.shape(decode_output)[0],tf.shape(decode_output)[2]])) # step E\n",
    "    return tf.convert_to_tensor(output),tf.convert_to_tensor(out_state_h),tf.convert_to_tensor(out_state_c),tf.convert_to_tensor(attention_weights),tf.convert_to_tensor(context_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FHrurjUMGAi"
   },
   "source": [
    "<font color='blue'>**Decoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NV-x31rj6Hc4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "        super().__init__()\n",
    "\n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.score_fun = score_fun\n",
    "        self.input_length = input_length\n",
    "        self.dec_units = dec_units\n",
    "        self.att_units = att_units\n",
    "        self.onestepdecoder=One_Step_Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state):\n",
    "#         print(input_to_decoder.shape)\n",
    "        output_tensor = tf.TensorArray(tf.float32,size=input_to_decoder.shape[1],name='output_tensor')\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        \n",
    "        #Iterate till the length of the decoder input\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            # Store the output in tensorarray\n",
    "        for time in range(input_to_decoder.shape[1]):\n",
    "#             print(decoder_hidden_state)\n",
    "            output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector = self.onestepdecoder(input_to_decoder[:,time:time+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n",
    "            output_tensor = output_tensor.write(time,output)\n",
    "         \n",
    "#         print(tf.transpose(output_tensor.stack(),[1,0,2]))\n",
    "        output_tensor = tf.transpose(output_tensor.stack(),[1,0,2])\n",
    "        return output_tensor\n",
    "        # Return the tensor array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC1T1EOoMTqC"
   },
   "source": [
    "<font color='blue'>**Encoder Decoder model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FfqBIe20MT3D"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "      def __init__(self,vocab_size_ita,vocab_size_eng,encoder_inputs_length,decoder_inputs_length,embedding_dim,enc_units,dec_units,score_fun,att_units,batch_size):\n",
    "            #Intialize objects from encoder decoder\n",
    "            super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "            self.encoder = Encoder(vocab_size_ita+1,embedding_dim,enc_units,encoder_inputs_length)\n",
    "            self.decoder = Decoder(vocab_size_eng+1,embedding_dim,encoder_inputs_length,dec_units,score_fun,att_units)\n",
    "#             self.decoder = Decoder(out_vocab_size=vocab_size_eng+1,embedding_size=embedding_dim,lstm_size=dec_units,input_length=encoder_inputs_length)\n",
    "#             self.dense   = Dense(vocab_size_eng, activation='softmax')\n",
    "            self.batch_size = batch_size\n",
    "            self.enc_units = enc_units\n",
    "      def call(self,data):\n",
    "        #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "        # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "        # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "        # return the decoder output\n",
    "        input,output = data[0], data[1]\n",
    "        initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
    "        decoder_output  = self.decoder(output,encoder_output, encoder_h, encoder_c)\n",
    "#         output   = self.dense(decoder_output)\n",
    "        return tf.convert_to_tensor(decoder_output)\n",
    "\n",
    "#         input,output = data[0], data[1]\n",
    "#         print(data)\n",
    "#         encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
    "#         decoder_output,_,_  = self.decoder(output, [encoder_h, encoder_c])\n",
    "#         output   = self.dense(decoder_output)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRxB-FDMJWL"
   },
   "source": [
    "<font color='blue'>**Custom loss function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QY_3izrXMs8y"
   },
   "outputs": [],
   "source": [
    "# Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def custom_lossfunction(targets,logits):\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    loss_ = loss_object(targets,logits)\n",
    "#     print(loss_)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#     print(mask)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint_path = \"checkpoint/model.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_best_only=True,monitor='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model weights loaded\n"
     ]
    }
   ],
   "source": [
    "# Implement teacher forcing while training your model. You can do it two ways.\n",
    "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
    "# if decoder input is \n",
    "# <start> Hi how are you\n",
    "# decoder output should be\n",
    "# Hi How are you <end>\n",
    "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
    "\n",
    "# or\n",
    " \n",
    "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
    "# Note: If you follow this approach some grader functions might return false and this is fine.\n",
    "\n",
    "#Create an object of encoder_decoder Model class, \n",
    "\n",
    "model  = encoder_decoder(vocab_size_rus,vocab_size_eng,encoder_inputs_length,decoder_inputs_length,50,256,256,'concat',16,batch_size)\n",
    "model.compile(optimizer=optimizer,loss=custom_lossfunction,metrics=['accuracy'],run_eagerly=True)\n",
    "\n",
    "# check if model weights present or not \n",
    "if os.path.isfile('checkpoint/model.ckpt.index'):\n",
    "    print('model weights loaded')\n",
    "    model.load_weights('checkpoint/model.ckpt')\n",
    "    \n",
    "train_steps=train.shape[0]//batch_size\n",
    "valid_steps=validation.shape[0]//batch_size\n",
    "model.fit_generator(train_dataloader,steps_per_epoch=train_steps,epochs=epochs,callbacks=[model_checkpoint_callback],verbose=1)\n",
    "\n",
    "#save model\n",
    "#tf.keras.models.save_model(model,'save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = { token[1]:token[0] for token in tokenizer_eng_out.word_index.items()}\n",
    "\n",
    "def attentionPlot(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "#     print(predicted_sentence)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels(['']+predicted_sentence.split(), fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels(['']+sentence.split(), fontdict=fontdict)\n",
    "    plt.show()\n",
    "    \n",
    "def predictTask(input_sentence,model):\n",
    "    attention_plot = np.zeros((encoder_inputs_length, decoder_inputs_length))\n",
    "\n",
    "    '''\n",
    "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "    E. Call plot_attention(#params)\n",
    "    F. Return the predicted sentence\n",
    "    '''\n",
    "    encoder_seq = tf.convert_to_tensor(pad_sequences(tokenizer_rus.texts_to_sequences([input_sentence]), maxlen=encoder_inputs_length, dtype='int32', padding='post'))\n",
    "    initial_state=model.layers[0].initialize_states(batch_size)\n",
    "    \n",
    "    enc_output, enc_state_h, enc_state_c = model.layers[0](encoder_seq,initial_state)\n",
    "    start = np.zeros((1,1))\n",
    "    predicted = ''\n",
    "    states_values = [enc_state_h, enc_state_c]\n",
    "    startFlag=True\n",
    "    for i in range(decoder_inputs_length):\n",
    "        if start[0][0] != 1 or startFlag == True:  \n",
    "            startFlag = False\n",
    "            predicted_out,out_state_h,out_state_c,attention_weights,context_vector = model.layers[1].onestepdecoder(start, enc_output, states_values[0],states_values[1])\n",
    "\n",
    "            states_values = [out_state_h,out_state_c]\n",
    "            \n",
    "            start = np.reshape(np.argmax(predicted_out), (1, 1))\n",
    "            predicted+=index_word[start[0][0]] + ' '\n",
    "            attention_plot[i] = tf.reshape(attention_weights, (-1, )).numpy()\n",
    "        else:\n",
    "            return predicted,attention_plot\n",
    "       \n",
    "    return predicted ,attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input russian string:  дай её мне\n",
      "Predicted Output string:  give it to me <end> \n",
      "True Output string:  give it to me <end>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_input_string = validation.sample(1).values[0]\n",
    "print('Input russian string: ',predict_input_string[0])\n",
    "predicted,attention_plot = predictTask(predict_input_string[0],model)\n",
    "print('Predicted Output string: ',predicted)\n",
    "print('True Output string: ',predict_input_string[2])\n",
    "attention_plot = attention_plot[:len(predicted.split()[:-1]), :len((predict_input_string[0]).split())]\n",
    "attentionPlot(attention_plot,predicted,predict_input_string[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1kN9ZWViQNMB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]C:\\Users\\Dhananjay\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Dhananjay\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Dhananjay\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:04<00:00, 15.57it/s]\n"
     ]
    }
   ],
   "source": [
    "#Sample example\n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "sample_test  = validation.sample(1000)\n",
    "bleu_score = []\n",
    "for datapoint in tqdm(sample_test.values):\n",
    "    predicted,attention_plot = predictTask(datapoint[0],model)\n",
    "    predicted = predicted.split()[:-1]\n",
    "    actual = [datapoint[2].split()[:-1]]\n",
    "    bleu_score.append(bleu.sentence_bleu(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Bleu score for concat model is:  0.5970476272110348\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Bleu score for concat model is: \",np.mean(np.array(bleu_score)))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2SeqImplementation__Assignment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
